### 部署kafka，用于接收filebeat从客户端收集的日志
* http://kafka.apache.org
>使用Kafka进行日志传输的原因在于其有数据缓存的能力，并且它的数据可重复消费，Kafka本身具有高可用性，能够很好的防止数据丢失.
* 安装kafka
```
tar -xzf kafka_2.11-0.11.0.1.tgz -C /opt
mv  kafka_2.11-0.11.0.1 kafka
cd /opt/kafka
```
* 修改配置
>vim config/zookeeper.properties
```
dataDir=/data/zookeeper/data
```
>vim config/server.properties
```
log.dirs=/data/kafka-logs
```

* 启动zookeeper
```
nohup bin/zookeeper-server-start.sh config/zookeeper.properties &
```

* 启动kafka
```
nohup bin/kafka-server-start.sh config/server.properties &
```

* 查看主题列表
```
bin/kafka-topics.sh --list --zookeeper localhost:2181
```
* 通过kafka命令行查看客户端消费消息
```
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
```

### 安装logstash
>主要用于进一步过滤处理filebeat收集的日志内容
* https://www.elastic.co/guide/en/logstash/6.7/introduction.html
```
rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
```
```
cat > /etc/yum.repos.d/logstash.repo <<EOF
[logstash-6.x]
name=Elastic repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
EOF
```
```
yum install -y logstash
```

* 配置logstash从kafka读取数据写入到elasticsearch
>vim /etc/logstash/conf.d/kafka-test.conf
```
input {
  kafka {
    bootstrap_servers => "172.31.37.224:9092"
    topics => ["system-messages"]
    codec => "json"
    type => "system-messages"
  }

  kafka {
    bootstrap_servers => "172.31.37.224:9092"
    topics => ["tomcat_catalina"]
    codec => "json"
    type => "tomcat_catalina"
  }
}

output {
  if [type] == "system-messages" {
    elasticsearch {
      hosts => ["172.31.40.180:9200"]
      index => "system-messages" 
    }
  }

  if [type] == "tomcat_catalina" {
    elasticsearch {
      hosts => ["172.31.40.180:9200"]
      index => "tomcat_catalina" 
    }
  }
}
```
```
systemctl start logstash
systemctl enable logstash
```