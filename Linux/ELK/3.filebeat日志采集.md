### 安装filebeat
* https://www.elastic.co/guide/en/beats/filebeat/6.7/index.html
* https://my.oschina.net/ch66880/blog/1619026
* https://www.cnblogs.com/cjsblog/p/9495024.html
```
rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch
```
```
cat > /etc/yum.repos.d/filebeat.repo<<EOF
[elastic-6.x]
name=Elastic repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
EOF
```
```
yum install filebeat
```


* 配置filebeat
>vim /etc/filebeat/filebeat.yml
```
filebeat.inputs:
- type: log
  paths:
    - /var/log/messages
  fields:
    log_topic: system-messages

- type: log
  paths:
    - /usr/local/tomcat/logs/catalina.out
  #合并whitespace (same as [\t\n\f\r ])开头的到非whitespace开头下面
  multiline.pattern: '^\s'
  multiline.match: after 
  ##合并java stack多行日志事件以"["中括号开头分隔
  #multiline.pattern: '^\['
  #multiline.negate: true
  #multiline.match: after
  fields:
    log_topic: tomcat_catalina

#过滤消息内容 只包含指定字段
#processors:
# - include_fields:
#     fields: ["message"]

output.kafka:
  hosts: ["172.31.37.224:9092"]
  topic: '%{[fields.log_topic]}'   #设置kafka中的主题名

#output.logstash:
#  hosts: ["172.31.37.224:5044"]
#  index: '%{[fields.log_topic]}'

#output.elasticsearch:
#  hosts: ["172.31.40.180:9200"]
#  index: '%{[fields.log_topic]}'

#默认以json格式控制台输出
#output.console:
#  pretty: true

#以文本格式控制台输出
#output.console:
#  codec.format:
#    string: '%{[@timestamp]} %{[message]}'
```

* 启动filebeat
```
filebeat test config
systemctl start filebeat
```


### Moudels
>Filebeat提供了一套预构建模块，您可以在5分钟内快速实施和部署日志监视解决方案，并附带示例仪表板和数据可视化

>必要条件：确保己经安装elk+filebeat,确认elastichsearch和kibana己启动

* 开启filebeat modules
>vim /etc/filebeat/filebeat.yml 添加modules配置：
```
filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml

filebeat.modules:
- module: nginx
  access:
    var.paths: ["/data/logs/nginx/admin-center.fncul.com.access.log"]
    fields:
      log_topic: nginx-admin-center-access
  error:
    var.paths: ["/data/logs/nginx/admin-center.fncul.com.error.log"]
    fields:
      log_topic: nginx-admin-center-error

output.kafka:
  hosts: ["172.31.37.224:9092"]
  topic: '%{[fields.log_topic]}'      
```
```
#命令行开启modules
#filebeat modules enable nginx
#filebeat modules list

#在启动filebeat时开启modules
#filebeat --modules nginx,mysql,system
```

* 为elasticsearch加载modules索引模板，kibana加载示例dashboards，如果filebeat output不是elasticsearch需要手动加载（须临时关闭其它的output）
  * https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-template.html#load-template-manually
  * https://www.elastic.co/guide/en/beats/filebeat/current/load-kibana-dashboards.html#load-dashboards-logstash
```
# filebeat output为elasticsearch
#filebeat setup -e
#filebeat setup --pipelines --modules nginx

# 手动加载index template到elasticsearch
filebeat setup --template -E output.kafka.enabled=false -E 'output.elasticsearch.hosts=["172.31.40.180:9200"]'

# 手动加载dashboards到Kibana.
filebeat setup -e \
  -E output.kafka.enabled=false \
  -E output.elasticsearch.hosts=['172.31.40.180:9200'] \
  #-E output.elasticsearch.username=filebeat_internal \
  #-E output.elasticsearch.password=YOUR_PASSWORD \
  -E setup.kibana.host=172.31.40.180:5601


# 手动加载ingest pipelines（日志获取管道）到elasticsearch
filebeat setup --pipelines --modules nginx -E output.kafka.enabled=false -E 'output.elasticsearch.hosts=["172.31.40.180:9200"]'
#如果使用logstash pipelines替代ingest pipelines跳过这一步

# 配置logstash pipelines
https://www.elastic.co/guide/en/logstash/6.7/use-ingest-pipelines.html
https://www.elastic.co/guide/en/logstash/6.7/use-ingest-pipelines.html
# filebeat->kafka-logstash pipelines
https://www.elastic.co/guide/en/logstash/6.7/use-filebeat-modules-kafka.html
```



* 启动filebeat
```
filebeat test config
systemctl start filebeat
```