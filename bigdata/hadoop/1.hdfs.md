* https://hadoop.apache.org/docs/r3.2.3/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html
* https://hadoop.apache.org/docs/r1.0.4/cn/hdfs_design.html
* https://www.w3cschool.cn/hadoop/xvmi1hd6.html

> HDFS是一个高可靠、高吞吐量的分布式文件系统

# 组件
* NameNode
  - 存储文件元数据,如文件名、目录结构、文件属性，每个文件的块列表和块所在的DataNode，以及客户端对文件的访问
  - Namenode是所有HDFS元数据的仲裁者和管理者，用户数据永远不会流过Namenode
  - 心跳检测：从集群中的每个DataNode接收心跳信号和块状态报告(Blockreport)
  - EditLog: 事务日志来持续记录文件系统元数据的每一个更改, EditLog文件位于NameNode本地磁盘
  - FsImage: 存储整个文件系统名称空间(包括块到文件和文件系统属性的映射)，FsImage文件位于NameNode本地磁盘

* Secondary NameNode
  - 每隔一段时间对NameNode元数据备份

* DataNodes
  - 在本地文件系统存储文件块数据，以及文件块数据的校验和
  - 流水线复制数据复制：用户可以指定某个文件的副本数，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并在同时转发给下一个Datanode节点，数据以流水线的方式从前一个Datanode复制到下一个
  - 副本存放策略：HDFS采用一种称为机架感知(rack-aware)的策略来改进数据的可靠性、可用性和网络带宽的利用率。为了降低整体的带宽消耗和读取延时，HDFS会尽量让读取程序读取离它最近的副本。如果在读取程序的同一个机架上有一个副本，那么就读取该副本。默认的安装假定所有的节点属于同一个机架。

* HDFS Client
  - 用户将文件写入HDFS Client本地磁盘作为临时文件缓存
  - 当临时文件大小达到一个 block 大小时，HDFS client 通知 NameNode，申请写入文件
  - NameNode 接收到HDFS Client请求后， 在 HDFS 的文件系统中创建一个文件，并把该 block id 和要写入的 DataNode 的列表返回给客户端
  - 客户端收到block id 和要写入的 DataNode 的信息后，将临时文件写入 DataNodes 


# hdfs架构
![image](https://hadoop.apache.org/docs/r3.2.3/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png)


# [hdfs伪集群](https://hadoop.apache.org/docs/r3.2.3/hadoop-project-dist/hadoop-common/SingleCluster.html#Pseudo-Distributed_Operation)
### [配置hadoop](https://hadoop.apache.org/docs/r3.2.3/hadoop-project-dist/hadoop-common/ClusterSetup.html#Configuring_Hadoop_in_Non-Secure_Mode)
> vim share/hadoop/hdfs/hadoop-hdfs-3.3.2.jar 查看默认配置文件 hdfs-default.xml
* etc/hadoop/core-site.xml:
```
<configuration>
    <!--hdfs监听地址-->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://172.31.14.200:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/data/hadoop/data</value>
    </property>
</configuration>
```
* etc/hadoop/hdfs-site.xml:
```
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.permissions</name>
        <value>false</value>
    </property>
</configuration>
```

### 格式化hdfs文件系统
```
bin/hdfs namenode -format
```

### 启动hdfs: NameNode、DataNode进程
```
sbin/start-dfs.sh

# 日志写入: $HADOOP_LOG_DIR directory (defaults to $HADOOP_HOME/logs)

jps #查看java进程
```
* NameNode Web
```
http://localhost:9870/
```
* 停止hdfs
```
sbin/stop-dfs.sh
```

### 在本地，运行MapReduce示例job
* 创建任务需求的目录
```
bin/hdfs dfs -mkdir /user
bin/hdfs dfs -mkdir /user/<username>
```
* 拷贝输入文件到hdfs分布式文件系统
```
bin/hdfs dfs -mkdir input
bin/hdfs dfs -put etc/hadoop/*.xml input
```
* 运行MapReduce示例程序
```
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar grep input output 'dfs[a-z.]+'
```
* 检查输出文件
```
bin/hdfs dfs -get output output
cat output/*

# or:
#bin/hdfs dfs -cat output/*
```

# [HDFS command](https://hadoop.apache.org/docs/r3.2.3/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html)
```
Usage: hdfs [SHELL_OPTIONS] COMMAND [GENERIC_OPTIONS] [COMMAND_OPTIONS]

bin/hdfs -help
bin/hdfs fs -put README.d /
```