* https://hbase.apache.org/book.html#quickstart_fully_distributed
* http://abloz.com/hbase/book.html#distributed

# 主机列表
hadoop01 | hadoop02 | hadoop03 
---|---|---
hbase master | hbase backup | 
regionserver | regionserver | regionserver

# 配置/etc/hosts
```
10.10.62.120  hadoop01
10.10.90.244  hadoop02
10.10.126.148 hadoop03
```
```
hostnamectl --static set-hostname hadoop01
hostnamectl --static set-hostname hadoop02
hostnamectl --static set-hostname hadoop03
```

# 安装依赖
* 安装zookeeper集群
* 安装hbase
```
chown -R hadoop.hadoop /usr/local/hbase/
```

# 配置无密码 SSH 访问
```
su - hadoop
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys
ssh localhost
ssh hadoop01
ssh hadoop02
ssh hadoop03
```


# 配置hbase分布式集群
* conf/hbase-env.sh
```sh
# 指定jdk安装目录
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-1.amzn2.0.2.x86_64
# 不使用hbase自带的zookeeper
export HBASE_MANAGES_ZK=false
```

* vim [conf/hbase-site.xml](https://hbase.apache.org/book.html#config.files) 
```xml
<configuration>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property>
  <property>
    <name>hbase.rootdir</name>
    <value>hdfs://data-test/hbase</value> <!--拷贝hadoop配置文件到hbase conf目录下-->
  </property>
  <property>
    <name>hbase.zookeeper.quorum</name>
    <value>hadoop01:2181,hadoop02:2181,hadoop03:2181</value>
  </property>
  <property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>/data/zookeeper/data</value>
  </property>
   <property>
    <name>hbase.master</name>
    <value>16000</value>
  </property>
  <property>
    <name>hbase.tmp.dir</name>
    <value>./tmp</value>
  </property>
  <property>
    <name>hbase.unsafe.stream.capability.enforce</name>
    <value>false</value>
</configuration>
```

* conf/regionservers
```
hadoop01
hadoop02
hadoop03
```

* conf/backup-masters, 在conf/中创建一个名为backup-masters的新文件
```
hadoop02
```

* HDFS客户端配置
```
cp core-site.xml hdfs-site.xml /usr/local/hbase/conf/
```

# 分发配置到其它节点
```
scp -r conf/ hadoop@hadoop02:/usr/local/hbase/
scp -r conf/ hadoop@hadoop03:/usr/local/hbase/ 
```

# 启动hbase
* 启动master
```
[hadoop@hadoop01 hbase]$ bin/hbase-daemon.sh start master
```
* 启动regionserver
```
[hadoop@hadoop01 hbase]$ bin/hbase-daemon.sh start regionserver
[hadoop@hadoop02 hbase]$ bin/hbase-daemon.sh start regionserver
[hadoop@hadoop03 hbase]$ bin/hbase-daemon.sh start regionserver
```
* 启动backup-master
```
[hadoop@hadoop02 hbase]$ bin/hbase-daemon.sh start master
```

* 一键启停所有节点
```
bin/start-hbase.sh
bin/stop-hbase.sh
```