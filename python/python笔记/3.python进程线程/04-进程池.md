### 进程池子
 
 * 当你成千上万的业务需要创建成千上万的进程时，我们可以提前定义一个进程池
 
*   from multiprocessing import Pool
 
   *    p = Pool(10) #进程池创建方式，类似空任务队列
   *    p.apply(func,args) #阻塞
      *     func：func指明该进程池种的进程要工作的函数
      *     args：不定长接收进程池中进程工作函数的参数
   *    p.apply_async(func,args) #非阻塞方式
      - func：func指明该进程池种的进程要工作的函数
      - args：不定长接收进程池中进程工作函数的参数
   *    p.close() 
      *     关闭进程池，不再接收新的任务了。
   *    p.join() **
      *     进程池里的进程资源要在关闭进程之后回收
   *    阻塞：单进程 | 串行 | 同步 | 多个进程可以排着队
      *     apply
      *     同一时间只能有一个进程来工作，其他进程等待这个进程的工作函数有了返回结果才能开启工作。
   *    非阻塞：多进程 | 并发 | 异步
      *     apply_async
      *     会在CPU核心数的基础上立即调用所有可用进程池中的进程资源来工作
 
*   apply：
 
   *    获取子进程返回值
 
   *    直接获取这个函数的返回值即可
 
      ```python
      for var in range(12):
        res.append(p.apply(func=work,args=(var,)))
      ```
 
*   ret = apply_async
 
   *    非阻塞多进程执行之后返回的是一个抽象的进程返回结果
   *    我们需要再次对这个进程返回结果再实际获取才可以拿到进程池工作之后的返回值
      *     ret.get() 拿到进程池进程执行之后的返回结果
 
*   避免了进程多次创建而带来的效率上的损耗


### 进程池
```python
from multiprocessing import Pool,current_process
#semphore 信号量， 控制进程间同步的
#Pool 批量创建多个进程
 
def work_a():
    for var in range(50000000):
        1 + 1
    print('AAAAA当前进程是:',current_process().name)
 
def work_b():
    for var in range(10000000):
        1 + 1
    print('BBBBB当前进程是:',current_process().name)
 
def main():
    p = Pool(3) #一个含有3个进程的进程池
 
    for var in range(5):
        p.apply_async(func=work_a)
        #p.apply(func=work_a)
        #阻塞形式:每一个进程池里的进程再执行的时候，只有等待上一个结束了下一个才会执行
            #阻塞是为了等待上一个工作进程有返回值，下一个进程才会执行
 
#进程池会不会三个进程，同时执行一个数据量大的函数
 
    for var in range(5):
        #p.apply_async(func=work_b)
        p.apply(func=work_b)
    #p.apply_async(func=,args=)
 
    p.close() #关闭进程池
    p.join() #回收进程池中进程资源
 
 
if __name__ == '__main__':
    main()
```

### 进程池返回值
```python
from multiprocessing import Pool,current_process
import time
def work(num):
    for var in range(100000000):
        pass
    print('当前进程是:',current_process().name)
    return num
 
def main():
    start = time.time()
    p = Pool(1)
    res = []
 
    for var in range(12):
        #res.append(p.apply(func=work,args=(var,)))
        res.append(p.apply_async(func=work,args=(var,)))
        #非阻塞的话 
        #Process(target=,)
         
    #time.sleep(0.5)
    #print('-------')
 
    for _p in res:
        print(_p.get()) #一定要获取到进程的返回值
    #print('--------')
    p.close()
    p.join()
    end = time.time()
    print('程序耗时:%.2fs' % (end-start))
if __name__ == '__main__':
    main()
```

### 进程池返回结果
```python
from multiprocessing import Pool,current_process
import time
def work(num):
    # for var in range(100000000):
    #     pass
    print('当前进程是:',current_process().name)
    return num
 
def main():
    start = time.time()
    p = Pool(4)
    res = []
 
    #res = p.map(work,range(10)) #阻塞
        #10次，
        #每一个序列都 会作为map创建出来的进程参数传递进去
    res = p.map_async(work,range(10)) #非阻塞
        #返回的res是一个抽象的返回结果
    res = res.get()
    p.close()
    p.join()
    end = time.time()
    print(res)
    print('程序耗时:%.2fs' % (end-start))
if __name__ == '__main__':
    main()
```